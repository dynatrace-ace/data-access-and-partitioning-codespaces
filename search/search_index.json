{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"1. About","text":"<p>Support Policy</p> <p>Support is provided via GitHub issues only. The materials provided in this repository are offered \"as-is\" without any warranties, express or implied. Use them at your own risk.</p>"},{"location":"#introduction","title":"Introduction","text":"<p>Imagine you're stepping into a real world engagement with a customer who is preparing to migrate from gen 2 to the gen 3 platform. The main question is \"what do I need to do\"?</p> <p>The customer has a Kubernetes cluster running two applications:</p> <ul> <li>Easytrade \u2013 a trading platform with multiple microservices</li> <li>Hipstershop \u2013 a demo e-commerce app used for observability testing</li> </ul> <p>These apps are deployed across different namespaces and environments, and your mission is to help the customer modernize their observability strategy using Dynatrace Gen 3 capabilities.</p>"},{"location":"#what-to-expect","title":"What to Expect?","text":"<p>Throughout the labs, you\u2019ll take on the role of a Dynatrace expert working directly with the customer. Each lab represents a critical phase of the migration journey, and by completing them, you\u2019ll gain hands-on experience with:</p> <ul> <li>Extracting and enriching metadata</li> <li>Designing and implementing scalable IAM strategy</li> <li>Creating precise data filters using Segments</li> <li>Partitioning logs for performance and cost efficiency</li> <li>Allocating observability costs across teams and services</li> </ul> <ul> <li>Yes! let's begin </li> </ul>"},{"location":"2-getting-started/","title":"2. Getting started","text":"<p>Requirements</p> <ul> <li>A Grail enabled Dynatrace SaaS Tenant (sign up here).</li> <li>A GitHub account to interact with the demo repository.</li> </ul>"},{"location":"2-getting-started/#1-prerequisites-before-launching-the-codespace","title":"1. Prerequisites before launching the Codespace","text":"<p>You will need to provide the following variables during the configuration of the codespace:</p> <ul> <li>DT_TENANT (https://abc123.live.dynatrace.com or sprint -&gt; https://abc123.sprint.dynatracelabs.com no apps in the URL)</li> <li>MONACO_TOKEN</li> <li>CLIENT_ID</li> <li> <p>CLIENT_SECRET</p> </li> <li> <p>Prepare the API token (TENANT_TOKEN) with permissions</p> </li> <li>CaptureRequestData</li> <li>credentialVault.read</li> <li>credentialVault.write</li> <li>DataExport</li> <li>DataPrivacy</li> <li>ReadConfig</li> <li>settings.read</li> <li>settings.write</li> <li>WriteConfig</li> <li>ExternalSyntheticIntegration</li> <li>events.ingest</li> <li>slo.read</li> <li>slo.write</li> <li>Prepare OAuthClient (CLIENT_SECRET)</li> <li>app-engine:apps:run</li> <li>app-engine:apps:install</li> <li>automation:calendars:read</li> <li>automation:calendars:write</li> <li>automation:rules:write</li> <li>automation:rules:read</li> <li>automation:workflows:run</li> <li>automation:workflows:write</li> <li>automation:workflows:read</li> <li>settings:schemas:read</li> <li>settings:objects:write</li> <li>settings:objects:read</li> </ul>"},{"location":"2-getting-started/#2-create-dynatrace-api-tokens-for-kubernetes-observability","title":"2. Create Dynatrace API Tokens for Kubernetes Observability","text":"<p>This codespace has everything automated for you so you can focus on what matters. You'll need two tokens:</p> <ul> <li>DT_OPERATOR_TOKEN</li> <li>DT_INGEST_TOKEN</li> </ul> <p>We will get this two very easy from the Kubernetes App.</p>"},{"location":"2-getting-started/#21-get-the-operator-token-and-the-ingest-token-from-the-kubernetes-app","title":"2.1. Get the Operator Token and the Ingest Token from the Kubernetes App","text":"<ol> <li>Open the Kubernetes App (CTRL + K then type Kubernetes for fast access)</li> <li>Select the + Add cluster button</li> <li>Scroll down to the section Install Dynatrace Operator</li> <li>Click on generate Token for the 'Dynatrace Operator' and save it to your Notepad</li> <li>Click on generate Token for the 'Data Ingest Token' and save it to your Notepad</li> <li>You can close the Kubernetes App, we don't need it, we just needed the tokens.</li> </ol> <p>Let's launch the Codespace</p> <p>Now we are ready to launch the Codespace!</p> <ul> <li>Let's launch Codespaces</li> </ul>"},{"location":"3-codespaces/","title":"3. Codespaces","text":"<p>This codespace is powered by the Dynatrace Enablement Framework, this means that this codespace:</p> <ul> <li>can run in github codespaces, as a remote container or locally as docker container</li> <li>is crosscompiled for AMD and ARM architectures</li> <li>follows a set of standards and best practices for enhancing the user experience</li> </ul> <p>Want to learn more about it? We invite you to read this documentation</p>"},{"location":"3-codespaces/#1-codespaces-configuration","title":"1. Codespaces configuration","text":""},{"location":"3-codespaces/#2-while-the-codespace-is-set-up-for-you-learn-powerful-usecases-with-dynatrace","title":"2. While the Codespace is set-up for you, learn powerful usecases with Dynatrace","text":"<p>We know your time is very valuable. This codespace takes around 6 minutes to be fully operational. A local Kubernetes (kind) cluster monitored by Dynatrace will be configured and in it a sample application, the TODO app will be deployed. To make your experience best, we are also installing and configuring tools like:</p> <p>k9s kubectl helm node jq python3 gh</p> <p></p>"},{"location":"3-codespaces/#3-explore-what-has-been-deployed","title":"3. Explore what has been deployed","text":"<p>Your Codespace has now deployed the following resources:</p> <ul> <li> <p>A local Kubernetes (kind) cluster monitored by Dynatrace, with some pre-deployed apps   that will be used later in the demo.</p> </li> <li> <p>After a couple of minutes, you'll see this screen in your codespaces terminal. It contains the links to the local expose labguide and the UI of the application which we will be doing our Hands-On training.   </p> </li> </ul>"},{"location":"3-codespaces/#4-tips-tricks","title":"4. Tips &amp; Tricks","text":""},{"location":"3-codespaces/#navigating-in-your-local-kubernetes","title":"Navigating in your local Kubernetes","text":"<p>The client <code>kubectl</code> and <code>k9s</code>are configured so you can navigate in your local Kubernetes like butter. </p>"},{"location":"3-codespaces/#5-troubleshooting","title":"5. Troubleshooting","text":""},{"location":"3-codespaces/#showing-open-ports-in-the-container","title":"Showing open ports in the container","text":"<p>There is a helper function loaded in the shell to see the open ports in the dev.container.</p> <pre><code>showOpenPorts(){\n  sudo netstat -tulnp\n}\n</code></pre> <pre><code>kubectl get pods -n dynatrace\n</code></pre> <ul> <li>Let's start our enablement</li> </ul>"},{"location":"4-slice-and-dice/","title":"4. Slice And Dice","text":""},{"location":"4-slice-and-dice/#slice-dice","title":"Slice &amp; Dice","text":""},{"location":"4-slice-and-dice/#objectives","title":"Objectives","text":"<ul> <li>Work with an existing customer scenario presented previously.</li> <li>Learn how to extract and map:</li> <li>\ud83d\udccb Requirements</li> <li>\ud83d\udcd0 Dimensions</li> <li>\ud83d\udda5\ufe0f Technologies</li> </ul>"},{"location":"4-slice-and-dice/#step-1-understand-the-requirements-interactive-discovery","title":"Step 1: Understand the \ud83d\udccb Requirements (Interactive Discovery)","text":"<p>The customer requirements are:</p> <ul> <li>Teams should only access their own apps, those apps being easytrade and hipstershop. This includes ALL DATA.</li> <li>Both easytrade and hipstershop logs need a separate bucket. Think about routing rules for logs and their respective buckets considering that everything is deployed in a kubernetes environment.</li> <li>Customers needs to be able to easily navigate through Dynatrace interface and see their respective apps as well as app signals.</li> <li>Costs need to be split by each application to understand how much each team is spending on Observability overall.</li> </ul>"},{"location":"4-slice-and-dice/#what-now","title":"WHAT NOW?","text":"<p>What are some questions you would ask yourself before doing the hands on work?</p> Here's how you get there...  #### \ud83d\udd10 Access Control  Goal: Understand who should access what data. Think about all questions that you need to ask your customer to uncover this. For example:  - Who should be able to access which data sets? - Are there any restrictions based on data sensitivity or compliance? - Do different teams need isolated views of their own applications? - Do you need to go more granular than just the application view?  #### \ud83e\uddf1 Partitioning (Bucket Strategy)  Goal: Identify how different signals should be stored and if they should be separated.  - Can you think of reasons why logs might need to be stored in separate buckets? - What about log retention: should all logs be kept for the same duration? Usually that's not the case. - Based on log volume, would query performance be affected? - Could separating logs into their respective application buckets help with cost control? Do you think this is best practice?  #### \ud83c\udfaf Segmentation  Goal: Determine how data should be filtered and grouped for visibility.  - What would be the best way to split your customer's data for visibility? - Would you like to filter by app, environment, region, or business unit? What do you think is the best approach? - How would this affect your data access?  &gt; Think about the move from Management Zones to IAM + Segments. What can people have access to vs what can they only filter on?  #### \ud83d\udcb0 Cost Allocation  Goal: Understand how observability costs should be tracked and distributed.  - How would your customer like to allocate costs? - Should costs be split by application, team, or department? - Do you need a chargeback or showback model for budgeting?"},{"location":"4-slice-and-dice/#discover-dimensions","title":"Discover \ud83d\udcd0 Dimensions","text":"<p>\ud83d\udca1 Dimensions = metadata used to tag and organize observability data.</p> <p>Instructions:</p> <ol> <li>Copy the notebook: https://guu84124.apps.dynatrace.com/ui/document/v0/#share=06f00290-72b6-4a03-930d-5a7bf17de35e</li> <li>Explore metadata sources:</li> <li>Host Groups</li> <li>MZ rules</li> <li>Tag Rules      Look for tags that reveal dimensions like platform, app, stage, team, etc.</li> </ol> <p>Write down the dimensions you discover:</p> <ul> <li> </li> <li> </li> <li> </li> </ul>"},{"location":"4-slice-and-dice/#technologies","title":"\ud83d\udda5\ufe0f Technologies","text":"<p>Find out underlying technologies -&gt; in this case, we have K8s.</p> <p>\ud83d\udca1 Understand the infrastructure to enrich observability data.</p> <p>\ud83d\udd0d Questions to Ask</p> <ul> <li>What cloud providers are used? (e.g., AWS, GCP, on-prem)</li> <li>Is Kubernetes or serverless in use?</li> <li>What tagging strategies exist across environments?</li> <li>What Dynatrace metadata can be leveraged? (e.g., HOST_GROUPS)</li> </ul> <p>Different technologies require different set-ups and depending on whether something is on-prem or serverless, it will rqeuired a different kind of set up for each of these.</p>"},{"location":"4-slice-and-dice/#map-requirements-with-dimensions","title":"Map requirements with dimensions","text":"Requirement Dimension Data Access dt.security_context = easytrade (same for hipstershop) Partitioning k8s.namespace.name Segmentation segment for easytrade and hipstershop Cost Allocation dt.cost.costcenter = easytrade and dt.cost.product = easytrade (same for hipstershop)"},{"location":"4-slice-and-dice/#resources","title":"Resources","text":"<ul> <li>Slice and Dice</li> <li>Slice and Dice - Existing Customer Scenario</li> <li>Slice and Dice - Example Scenario</li> </ul> <ul> <li>Let's continue</li> </ul>"},{"location":"5-metadata-enrichment/","title":"5. Metadata enrichment","text":""},{"location":"5-metadata-enrichment/#metadata-enrichment","title":"Metadata Enrichment","text":""},{"location":"5-metadata-enrichment/#objectives","title":"\ud83c\udfaf Objectives","text":"<p>All participants will enrich observability data (entities, metrics, events, logs, etc.) with metadata fields such as:</p> <ul> <li><code>dt.security_context</code></li> <li><code>dt.cost.costcenter</code></li> <li><code>dt.cost.product</code> <p>The idea is to explore different enrichment strategies using Kubernetes and understand trade offs between approaches. If your cluster hasn't been activated yet for the new Kubernetes app, please do that manually.</p> </li> </ul>"},{"location":"5-metadata-enrichment/#step-1-understand-why-metadata-enrichment-matters","title":"Step 1: Understand Why Metadata Enrichment Matters","text":"<p>\ud83d\udca1 Enrichment helps with access control, cost allocation, segmentation, and governance. We are trying to make sure that observability data is tagged with meaningful context.</p> <p>Key Enrichment Targets:</p> <ul> <li>Entities (e.g., services, workloads)</li> <li>Metrics</li> <li>Events</li> <li>Logs</li> <li>Traces</li> </ul> <p>Questions to consider:</p> <ul> <li>What metadata do you need to enrich your data with?</li> <li>What level of granularity is required - namespace or workload?</li> <li>Do you want enrichment to be automatic, declarative, or manual?</li> <li>How will this metadata be used for IAM, cost control, and segmentation?</li> </ul>"},{"location":"5-metadata-enrichment/#step-2-explore-enrichment-strategies","title":"Step 2: Explore Enrichment Strategies","text":"<p>Use the guide: Enrichment Kubernetes</p> <p>\u2705 Option 1: Rely on Primary Grail Fields:</p> <ul> <li><code>k8s.namespace.name</code></li> <li><code>k8s.cluster.name</code></li> </ul> Pros Cons Use when Out-of-the-box (OOTB) Limited granularity Quick setup is needed No configuration needed Only namespace-level Simple IAM and segmentation <p>\ud83d\udfe1 Option 2: Use Namespace Annotations &amp; Labels</p> <p>How it works? Dynatrace Operator converts namespace-level metadata into enrichment fields.</p> Pros Cons Use when Declarative Only applies at namespace level Customer follows cloud-native tagging practices Moderate effort Requires Dynatrace configuration Needs more flexibility than OOTB fields Supports custom Primary Grail Tags <p>\ud83d\udd34 Option 3: Set Manual Pod Annotations</p> <p>How it works? Manually add annotations to pod definitions (e.g., in deployment YAML)</p> Pros Cons Use when Maximum granularity (workload-level) Requires code changes Need to segregate access or cost at workload level Full control over enrichment Higher effort Namespace-level granularity is not enough"},{"location":"5-metadata-enrichment/#summary-table","title":"Summary Table","text":"Approach Effort Granularity Flexibility Best For Primary Grail Fields \ud83d\udfe2 Low Namespace \ud83d\udd34 Limited Quick IAM &amp; Segments setup Namespace Annotations/Labels \ud83d\udfe1 Medium Namespace \ud83d\udfe1 Moderate Declarative tagging, cloud-native orgs Manual Pod Annotations \ud83d\udd34 High Workload \ud83d\udfe2 Maximum Fine-grained control, cost partitioning"},{"location":"5-metadata-enrichment/#step-3-try-it-out","title":"Step 3: Try It Out","text":"<p>Complete enrichment using all strategies.</p> <p>In Dynatrace, you can set up policy boundaries for fine-grained restrictions on the data level with the help of Primary Fields. By default, you can use <code>k8s.namespace.name</code> and <code>k8s.cluster.name</code>, but sometimes this is not enough and you need a more fine grained way to set up your boundaries. Primary Grail Tags will help you with this.</p> <p>Primary Grail tags are a small set of important, customer selected tags such as Kubernetes labels, AWS/Azure tags, or key organizational attributes that Dynatrace automatically attaches to all raw telemetry data at ingest, using the <code>primary_tags.*</code> prefix. This enrichment enables fast, consistent filtering, grouping, and permission management across all data, without complex joins or proprietary tagging rules. Primary Grail tags are centrally configured and ensure that cloud-native and business-relevant metadata is always available for queries, dashboards, and access control.</p> Primary Grail Field Primary Grail Tag What are they? Well defined OOTB fields for specific technologies A new tag on all telemetry data Purpose Data level access, here to auto enrich all signals and entities OOTB Enrichment of all signals including smartscape Nodes <p>Task 1: Automatic Enrichment via Kubernetes Metadata</p> <p>So, as we said, Dynatrace automatically enriches telemetry data as well as entities with Kubernetes metadata such as:</p> <ul> <li><code>k8s.cluster.name</code></li> <li><code>k8s.namespace.name</code></li> </ul> <p>Explore your customer's tenant to see how this works. Write down your analysis.</p> <p>Can you fetch entities and filter them by their <code>k8s.cluster.name</code> or <code>k8s.namespace.name</code>? ******__******</p> <p>Can you fetch all logs and filter them by their <code>k8s.cluster.name</code> or <code>k8s.namespace.name</code>? ******__******</p> <p>\ud83d\udca1 Tip: This is useful for OOTB IAM and Segment configurations.</p> <p>Now, think about a use case where a customer doesn't want to use these default Primary Grail Fields for whatever reason - they might not be granular or flexible enough. What would you do?</p> <p>If this is not enough and you'd like to go further and you require more configuration possibilities. Let's explore the enrichment strategy at source. You can enrich data by adding custom labels and annotations to your Kubernetes manifests. Dynatrace will pick these up and use them for tagging and filtering.</p> <p>Task 2: Automatic Enrichment via Kubernetes Metadata at Source</p> <p>You should ultimately enrich your deployment with:</p> <ul> <li><code>dt.security_context</code></li> <li><code>dt.cost.costcenter</code></li> <li><code>dt.cost.product</code></li> </ul> <p>How to do that you might ask? Well... Let's look at how customers manage modern cloud environments. In modern cloud-native environments, cloud tags, Kubernetes labels and namespaces classify systems using various aspects, like cost allocation, access control, application, and owner. In such environments, configuration-as-code principles are well established, including defining such tags as part of the system configuration.</p> <p>In K8s, annotations and labels are both key-value pairs used to attach metadata to objects like Pods, Services, and Deployments. Customers following cloud-native tagging best practices will define their partitioning with labels &amp; annotations, as follows:</p> <p></p> <p>Note that this is still very basic and limited. We'll add more as we go through this lab.</p> <p>You can use the K8s Enrichment settings to transform labels &amp; annotations into <code>dt.security_context</code>, <code>dt.cost.costcenter</code>, <code>dt.cost.product</code>.</p> <ol> <li>Go to Settings &gt; Topology Model &gt; Grail security context for monitored entities</li> <li>Filter by <code>dt.entity.cloud_application_namespace</code></li> <li>Change destination property from Management Zone to <code>dt.security_context</code></li> </ol> <p>This is needed in order for the enrichment to work. If you're wondering how come we already have the labels extracted, you can go to <code>Settings &gt; Cloud and Virtualization &gt; Kubernetes telemetry enrichment</code> and check the rule there. That rule is allowing us to propagate the label to <code>dt.security_context</code>, however, Grail doesn't know about it until we point the topology rule to it.</p> <p></p> <p>\ud83d\udca1 How it works? The Dynatrace Operator will take care of the enrichment when mutating the pod definition</p> <p></p> DQL <pre><code>fetch spans\n| filter k8s.workload.name == \"loginservice\"\n| fields start_time, span.id, k8s.workload.name, k8s.namespace.name, dt.security_context, dt.cost.costcenter, dt.cost.product\n| sort start_time DESC\n| limit 15\n</code></pre> <p>Task 3: Manual Pod Annotation for Granularity</p> <p>If you need workload-level granularity, manual annotations are required. For example, you want to be more specific on the product and cost center for the loginservice.</p> <p>\ud83d\udca1Note that:</p> <ul> <li>Manually set metadata.dynatrace.com pod annotations take precedence over metadata enrichment configurations</li> </ul> <p>Update your deployment manifest by following instructions below:</p> <ol> <li>SSH into your VM</li> <li>Run <code>kubectl edit deployment &lt;deploymentname&gt; -n easytrade</code> and add the annotations under <code>spec &gt; template &gt; metadata</code>. The pod will automatically be restarted and after a few minutes you will see a new one appear in your cluster as well as in the Dynatrace UI.</li> </ol> <pre><code>metadata:\n  annotations:\n    metadata.dynatrace.com/dt.security_context: \"easytrade\"\n    metadata.dynatrace.com/dt.cost.costcenter: \"platform\"\n    metadata.dynatrace.com/dt.cost.product: \"loginservice\"\n</code></pre> <p>Result:</p> <p> </p> <p>\u26a0\ufe0f Notes</p> <ul> <li>Namespace-level enrichment is easier but less granular.</li> <li>Workload-level enrichment gives full control but requires manual effort.</li> <li>Without proper annotations, filtering and cost allocation may be limited.</li> </ul>"},{"location":"5-metadata-enrichment/#resources","title":"Resources","text":"<ul> <li>Metadata Enrichment</li> <li>Keep an eye on the part that talks about Primary Grail Fields and Primary Grail Tags</li> <li>Metadata Enrichment - K8s</li> </ul> <ul> <li>Let's continue</li> </ul>"},{"location":"6-data-access/","title":"6. Data Access","text":""},{"location":"6-data-access/#data-access","title":"Data Access","text":""},{"location":"6-data-access/#the-easytrade-scenario","title":"The Easytrade scenario","text":"<p>Easytrade, a fast-growing fintech platform, has just expanded its operations across multiple regions and teams. With 13 microservices powering everything from login to trading, the platform is now managed by several specialized teams: infrastructure, observability, and application owners.</p> <p>As the company scales, so does the complexity of managing access to observability data. The infrastructure team needs full control over configurations, while application teams only need read access to their own services. Meanwhile, everyone should be able to view SLOs and dashboards.</p> <p>To avoid chaos and manual permission management, Easytrade decides to implement a scalable IAM strategy in Dynatrace, one that uses custom roles, policy boundaries, and group-based access control.</p> <p>Your main goal in this lab is to help Easytrade build this strategy from the ground up.</p>"},{"location":"6-data-access/#objectives","title":"\ud83c\udfaf Objectives","text":"<ul> <li>Understand how Dynatrace IAM works.</li> <li>Learn how to create and manage roles, policies, boundaries, and groups.</li> <li>Apply scoped access using <code>dt.security_context</code> and a management zone.</li> <li>Minimize maintenance effort by decoupling permissions from scopes.</li> </ul>"},{"location":"6-data-access/#approches","title":"Approches:","text":"Approach Effort Flexibility Comments Best For Default Dynatrace Policies \ud83d\udfe2 Low \ud83d\udd34 Limited Policies are automatically updated by Dynatrace, with new statements on new features New customers or new to policies, fine with \"roles\" being automatically updated Custom Policies \ud83d\udd34 High \ud83d\udfe2 Maximum Customers are maintaining custom policies, adding or removing statements on new/changing features Customers that are familiar with policies and want to keep full control on which permissions to grant or not"},{"location":"6-data-access/#approach-1-using-default-dynatrace-policies","title":"Approach 1 - Using Default Dynatrace Policies","text":""},{"location":"6-data-access/#exercice-1-create-a-boundary-for-easytrade","title":"Exercice 1: Create a boundary for \"Easytrade\"","text":"<p>Now that any Dynatrace User can access the default features, we want to allow users to access specific observability data.</p> <p>\ud83d\udca1We want to create a boundary for the 'Easytrade' app that will be attachable to any permission.</p> <p>Task 1: Create the boundary</p> <ol> <li>Navigate to the Account Management Portal &gt; Identity &amp; access management &gt; Policy management, and to the \"Boundaries\" tab</li> <li>Click on the \"+ Create boundary\" button</li> <li> <p>Fill the form:</p> </li> <li> <p>Boundary name: \"Easytrade\"</p> </li> <li>Boundary query:</li> </ol> Boundary query: <pre><code>storage:dt.security_context IN (\"easytrade\", \"EasyTrade\");\n// \"EasyTrade\" format comes from MZ format (grail security context for monitored entities)\nenvironment:management-zone IN (\"EasyTrade\");\n</code></pre> <ul> <li>Click on \"Save\"</li> </ul> <p></p>"},{"location":"6-data-access/#exercice-2-create-access-for-easytrade-readers","title":"Exercice 2: Create Access for Easytrade \"Readers\"","text":"<p>We now want to grant specific users with \"Readers\" access to Dynatrace. Allowing them to see data in the different apps.</p> <p>\ud83d\udca1We want to create a group for the 'Easytrade' app with read permissions.</p> <p>Task 1: Explore the default Dynatrace Policies</p> <ol> <li>Navigate to the Account Management Portal &gt; Identity &amp; access management &gt; Policy management</li> <li>Explore the different policies of category \"Data access\" and \"Dynatrace access\"</li> <li>Understand which policy is a good fit for Dynatrace \"Readers\"</li> </ol> <p>Task 2: Create a group for the Easytrade Readers</p> <ol> <li>Navigate to the Account Management Portal &gt; Identity &amp; access management &gt; Group management</li> <li>Click on the \"+ Create group\" button</li> <li> <p>Fill the form</p> </li> <li> <p>Name: \"[Readers] Easytrade\"</p> </li> <li> <p>Description: \"Grants reading permissions to observability data for the Easytrade team\"</p> </li> <li> <p>Click on \"Create\"</p> </li> </ol> <p></p> <p>Task 3: Assign the policy and boundary to the [Readers] Easytrade group</p> <ol> <li>On the newly created group edition page</li> <li>Click on the \"+ Permission\" button</li> <li> <p>Fill the form to grant access to Dynatrace:</p> </li> <li> <p>Permission name: \"Standard user\"</p> </li> <li>Scope: tick the \"Account (all environments)\" box</li> <li> <p>Boundaries: \"Easytrade\"</p> </li> <li> <p>Click on \"Save\"</p> </li> <li> <p>Add another permission to grant access data, click on \"+ Permission\" and fill the form:</p> </li> <li> <p>Permission name: \"All Grail data read access\"</p> </li> <li>Scope: tick the \"Account (all environments)\" box</li> <li> <p>Boundaries: \"Easytrade\"</p> </li> <li> <p>Click on \"Save\"</p> </li> </ol> <p> </p>"},{"location":"6-data-access/#exercice-3-create-access-for-easytrade-writers","title":"Exercice 3: Create Access for Easytrade \"Writers\"","text":"<p>We now want to grant specific users with \"Writers\" access to Dynatrace. Allowing them to edit monitoring configurations in the different apps.</p> <p>\ud83d\udca1We want to create a group for the 'Easytrade' app with writers permissions.</p> <p>Task 1: Create a custom policy for the Writers</p> <ol> <li>Navigate to the Account Management Portal &gt; Identity &amp; access management &gt; Policy management</li> <li>Click on \"+ Create policy\"</li> <li> <p>Fill the form</p> </li> <li> <p>Name: \"[Lab] Writers\"</p> </li> <li>Policy description: \"Statements granting write permissions\"</li> <li>Policy statement:</li> </ol> Write permissions on settings \u2013 Settings <pre><code>ALLOW settings:schemas:read;\nALLOW settings:objects:read, settings:objects:write;\nALLOW environment:roles:manage-settings;\n</code></pre> <ol> <li>Click on \"Save\"</li> </ol> <p></p> <p>Task 2: Create a group for the Easytrade Writers</p> <ol> <li>Navigate to the Account Management Portal &gt; Identity &amp; access management &gt; Group management</li> <li>Click on the \"+ Create group\" button</li> <li> <p>Fill the form</p> </li> <li> <p>Name: \"[Writers] Easytrade\"</p> </li> <li> <p>Description: \"Grants writers permissions to observability configurations for the Easytrade team\"</p> </li> <li> <p>Click on \"Create\"</p> </li> </ol> <p></p> <p>Task 3: Assign the policy and boundary to the [Writers] Easytrade group</p> <ol> <li>On the newly created group edition page</li> <li>Click on the \"+ Permission\" button</li> <li> <p>Fill the form:</p> </li> <li> <p>Permission name: \"[Lab] Writers\"</p> </li> <li>Scope: tick the \"Account (all environments)\" box</li> <li> <p>Boundaries: \"Easytrade\"</p> </li> <li> <p>Click on \"Save\"</p> </li> </ol> <p></p>"},{"location":"6-data-access/#exercice-4-assign-users-to-groups","title":"Exercice 4: Assign users to groups","text":"<p>We now want to test the permissions we created in previous lab exercises.</p> <p>\ud83d\udca1We will invite a separate email address and verify its access according to the assigned groups.</p> <p>Task 1: Create a test user email address</p> <ol> <li>Create or use another email address (such as a gmail address)</li> </ol> <p>Task 2: Verify the Readers permissions</p> <ol> <li>Navigate to the Account Management Portal &gt; Identity &amp; access management &gt; User management</li> <li>Click on the \"Invite users\" button</li> <li>Fill in the email address and assign the \"[Readers] Easytrade\" group</li> <li>Click on \"Invite\"</li> <li>Authenticate with this new user in a private window, and verify the permissions</li> </ol> <p></p> <p>\ud83d\udca1You can also navitage to Account Management Portal &gt; Identity &amp; access management &gt; Effective policies, to verify the policies and boundaries for your user.</p> <p></p> <p>Task 3: Verify the Writers permissions</p> <ol> <li>Navigate to the Account Management Portal &gt; Identity &amp; access management &gt; User management</li> <li>Edit your test user</li> <li>Add both [Readers] Easytrade and [Writers] Easytrade</li> <li>Click on \"Save\"</li> <li>Authenticate with this new user in a private window, and verify the permissions</li> </ol> <p></p> <p>\ud83d\udca1You can also navitage to Account Management Portal &gt; Identity &amp; access management &gt; Effective policies, to verify the policies and boundaries for your user.</p> <p></p> Approach 2 - Using Custom Policies  #### Exercise 1: Create Default User Policies  Default users get access to Dynatrace apps and basic usage features, but no data access.  **Tasks**  1. Create Policy: Default users   App access permissions \u2013 Apps Access <pre><code>ALLOW app-engine:apps:run WHERE shared:app-id IN (\n  \"dynatrace.appshell\",\n  \"dynatrace.launcher\",\n  \"dynatrace.dashboards\",\n  \"dynatrace.notebooks\",\n  \"dynatrace.logs\",\n  \"dynatrace.davis.problems\",\n  \"dynatrace.classic.logs.events\",\n  \"dynatrace.classic.dashboards\",\n  \"dynatrace.classic.problems\",\n  \"dynatrace.classic.data.explorer\",\n  \"dynatrace.classic.metrics\",\n  \"dynatrace.classic.smartscape\",\n  \"dynatrace.infraops\",\n  \"dynatrace.database.overview\",\n  \"dynatrace.extensions.manager\",\n  \"dynatrace.clouds\",\n  \"dynatrace.kubernetes\",\n  \"dynatrace.classic.hosts\",\n  \"dynatrace.classic.network\",\n  \"dynatrace.classic.technologies\",\n  \"dynatrace.classic.aws\",\n  \"dynatrace.classic.kubernetes\",\n  \"dynatrace.classic.containers\",\n  \"dynatrace.classic.extensions\",\n  \"dynatrace.classic.vmware\",\n  \"dynatrace.service.level.objectives\",\n  \"dynatrace.classic.slo\",\n  \"dynatrace.classic.releases\",\n  \"dynatrace.distributedtracing\",\n  \"dynatrace.services\",\n  \"dynatrace.classic.distributed.traces\",\n  \"dynatrace.classic.services\",\n  \"dynatrace.classic.profiling\",\n  \"dynatrace.classic.queues\",\n  \"dynatrace.classic.mda\",\n  \"dynatrace.classic.databases\",\n  \"dynatrace.classic.kubernetes.workloads\",\n  \"dynatrace.synthetic\",\n  \"dynatrace.error.inspertor\",\n  \"dynatrace.experience.vitals\",\n  \"dynatrace.classic.query.user.sessions\",\n  \"dynatrace.classic.synthetic\",\n  \"dynatrace.classic.web\",\n  \"dynatrace.classic.frontend\",\n  \"dynatrace.classic.session.replay\",\n  \"dynatrace.classic.session.segmentation\",\n  \"dynatrace.classic.mobile\",\n  \"dynatrace.classic.custom.applications\",\n  \"dynatrace.hub\",\n  \"dynatrace.segments.management\",\n  \"dynatrace.settings\",\n  \"dynatrace.classic.settings\",\n  \"dynatrace.classic.user.settings\",\n  \"dynatrace.classic.personal.access.tokens\",\n  \"dynatrace.learndql\"\n);\n</code></pre>   2. Create Policy: Basic Usage   Standard permissions <pre><code>ALLOW\n  state:app-states:delete,\n  state:app-states:read,\n  state:app-states:write,\n  state:user-app-states:read,\n  state:user-app-states:write,\n  state:user-app-states:delete,\n  state-management:user-app-states:delete,\n  state-management:user-app-states:delete-all,\n  document:documents:read,\n  document:documents:write,\n  document:documents:delete,\n  document:environment-shares:read,\n  document:environment-shares:write,\n  document:environment-shares:claim,\n  document:environment-shares:delete,\n  document:direct-shares:read,\n  document:direct-shares:write,\n  document:direct-shares:delete,\n  document:trash.documents:read,\n  document:trash.documents:restore,\n  document:trash.documents:delete,\n  unified-analysis:screen-definition:read,\n  storage:bucket-definitions:read,\n  storage:fieldset-definitions:read,\n  storage:filter-segments:read,\n  storage:filter-segments:write,\n  storage:filter-segments:delete,\n  hub:catalog:read,\n  app-engine:functions:run,\n  app-engine:edge-connects:read,\n  davis:analyzers:read,\n  davis:analyzers:execute,\n  notification:self-notifications:read,\n  geolocation:locations:lookup,\n  slo:slos:read,\n  slo:objective-templates:read;\n</code></pre>   3. Create Policy: Default Metrics Access   Workaround Infra&amp;Ops apps issues \u2013 Default Metrics Access <pre><code>ALLOW storage:metrics:read WHERE storage:metric.key IN (\n  \"dt.host.availability\",\n  \"dt.host.uptime\"\n);\n</code></pre>   4. Create Policy: Extensions Access   Network Devices in Infra&amp;Ops App <pre><code>ALLOW extensions:definitions:read, extensions:configurations:read\nWHERE extensions:extension-name IN (\n  \"com.dynatrace.extension.snmp-auto-discovery\"\n);\n</code></pre>   #### Exercise 2: Create Reader Role &amp; Policy  Policy: Readers   Read permissions \u2013 Basic Data <pre><code>ALLOW\n  storage:buckets:read,\n  storage:entities:read,\n  storage:smartscape:read,\n  storage:metrics:read,\n  storage:spans:read,\n  storage:logs:read,\n  environment:roles:logviewer,\n  storage:events:read,\n  storage:bizevents:read,\n  storage:user.events:read,\n  storage:user.sessions:read,\n  environment:roles:viewer,\n  app-settings:objects:read,\n  settings:objects:read,\n  settings:schemas:read,\n  extensions:definitions:read,\n  extensions:configurations:read;\n</code></pre>   #### Exercise 3: Create Writer Role &amp; Policies  Policy 1: Writers   Write permissions on settings \u2013 Settings <pre><code>ALLOW settings:objects:write, environment:roles:manage-settings;\n</code></pre>   Policy 2: Writers   Write permissions on extensions \u2013 Extensions <pre><code>ALLOW extensions:configurations:write, extensions:configuration.actions:write;\n</code></pre>   #### Exercise 4: Create Boundaries  Boundary 1   dt.security_context = easytrade <pre><code>storage:dt.security_context IN (\"easytrade\")\n</code></pre>   Boundary 2   management-zone = easytrade <pre><code>environment:management-zone IN (\"easytrade\")\n</code></pre>   #### Exercise 5: Create Groups &amp; Assign Policies  Groups to create:  - Default Users \u2192 assign all default policies (no boundary) - Easytrade Readers \u2192 assign Readers \u2013 Basic Data + easytrade boundary - Easytrade Writers \u2192 assign both Writers policies + easytrade boundary  #### Exercise 6: Assign Users to Groups  Group Membership Strategy  - Writers \u2192 must be in:   - Default Users   - Easytrade Readers   - Easytrade Writers - Readers \u2192 must be in:   - Default Users   - Easytrade Readers"},{"location":"6-data-access/#resources","title":"Resources","text":"<ul> <li>IAM Guide</li> </ul> <ul> <li>Let's continue</li> </ul>"},{"location":"7-data-segmentation/","title":"7. Data segmentation","text":""},{"location":"7-data-segmentation/#data-segmentation","title":"Data Segmentation","text":"<p>Moving from Management Zones to Segments</p> <p>As Easytrade continues to scale, their observability data grows exponentially. Teams are struggling to filter logs, metrics, and traces efficiently. While Management Zones helped in the past, we don't want them in the future ;) .</p> <p>Now, Easytrade is adopting Segments. They are a powerful new way to filter all types of data (not just entities) using dimensions like platform, app, and stage. These dimensions are already embedded in their Host Group definitions, and Segments will allow teams to slice data with precision, reduce noise, and improve performance.</p> <p>Your goal in this lab is to help Easytrade build Segments based on their Host Group naming convention and validate their effectiveness across logs, traces, metrics, and dashboards.</p>"},{"location":"7-data-segmentation/#learning-objectives","title":"\ud83c\udfaf Learning Objectives","text":"<ul> <li>Understand what Segments are and how they differ from Management Zones.</li> <li>Learn how to extract dimensions from Host Group names.</li> <li>Create Segments for platform, app, and stage.</li> <li>Apply Segments to filter logs, traces, metrics, and dashboards.</li> </ul>"},{"location":"7-data-segmentation/#exercise-1-understand-host-group-dimensions","title":"Exercise 1: Understand Host Group Dimensions","text":"<p>Host Groups often encode key dimensions used for filtering. Let's get some context.</p> <p>Easytrade uses the Host Group naming convention: <code>k8s_multi_prod</code></p> <p>This encodes:</p> <ul> <li>platform \u2192 k8s</li> <li>app \u2192 multi</li> <li>stage \u2192 prod</li> </ul> <p></p> <p>Host Group definition</p>"},{"location":"7-data-segmentation/#exercise-2-compare-management-zones-with-segments","title":"Exercise 2: Compare Management Zones with Segments","text":"<p>Management Zones filter entities. Segments filter everything. Let's have a look at both.</p> <ol> <li>Open Dynatrace and view all hosts.</li> <li>Apply a Management Zone filter.</li> <li>Observe how only entities are filtered.</li> </ol> <p></p> <p>All hosts within the environment</p> <p></p> <p>Filtered by Management Zone</p>"},{"location":"7-data-segmentation/#exercise-3-create-an-app-segment","title":"Exercise 3: Create an App Segment","text":"<p>While management zones have been used widely in Dynatrace to define access to data and filter data on a global level, in the latest Dynatrace they have been replaced by three new concepts, each tailored to satisfy the respective requirements of Enterprise environments:</p> <ul> <li>Data Partitioning (lab 5): Organize data logically and address performance and retention requirements.</li> <li>Data Access (lab 3): Stay flexible and meet compliance and security demands by defining fine-grained access to data and Dynatrace platform capabilities based on a user's context.</li> <li>Data Segmentation (lab 4): Provide real-time filtering on huge data sets without the need to define thousands of individual rules.</li> </ul> <p>In exercise 3 and all subsequent exercises, we will focus on exploring Segments.</p> <p>Let's start by creating a segment that will filter out all data connected to one of our applications - Easytrade.</p> <ol> <li>Navigate to <code>Settings &gt; Environment Segmentation &gt; Segments</code></li> <li>Create a new Segment</li> <li>Instructions are provided below</li> </ol> <p>Variable DQL query for App</p> <pre><code>fetch dt.entity.cloud_application_namespace\n| fields application_name = entity.name, tag = concat(\"app:\", entity.name)\n</code></pre> <p>Segment Filters</p> <p>App: <code>k8s.namespace.name = $application_name OR tag = $tag</code></p> <p></p> <p>Variable configuration for App segment</p> <p></p> <p>App segment configuration preview</p>"},{"location":"7-data-segmentation/#exercise-4-create-a-stage-segment","title":"Exercise 4: Create a Stage Segment","text":"<p>Extract stage from Host Group names and use it to filter all data.</p> <ol> <li>Go to Settings &gt; Environment Segmentation &gt; Segments</li> <li>Create a Platform Segment with provided instructions.</li> <li>Extract all possible values for Stage using the below DQL<ul> <li><code>fetch dt.entity.host_group| parse `entity.name`, \"\"\"LD:platform '_' LD:app '_' LD:stage\"\"\"| dedup platform| fields platform</code></li> </ul> </li> <li>Use <code>dt.host_group.id = *$stage</code> to filter all datapoints within the Host-Group</li> </ol> <p></p> <p>Variable configuration for Stage segment</p> <p></p> <p>Stage segment configuration preview</p> <p>Please note that filters such as <code>dt.host_group.id = *$stage</code> do not work for classic entities. You might get the following error if you try to apply the same filter to a <code>dt.entity.host</code> entity type - \"Wildcard \"*\" resulting in a \"startsWith\" operator not allowed, please change it in \"dt.host_group.id\" filter value definition.\". Please see below.</p> <p></p> <p>Nevertheless, this should work for smartscape 2.0 entities in their respective screens. Segments preview doesn't work at the moment for any entity but k8s entities should automatically be visible within the Kubernetes app. More information on how different classic and smartscape on grail entities are can be found here.</p>"},{"location":"7-data-segmentation/#exercise-5-validate-segments-with-smartscape-entities","title":"Exercise 5: Validate Segments with Smartscape entities","text":"<p>Use the K8s app to prove that App segment works with K8s entities.</p> <ol> <li>Opent the Kubernetes App</li> <li>Go to the Namespaces tab</li> <li>Apply the Application segment</li> </ol> <p></p> <p>Kubernetes entities in Grail</p>"},{"location":"7-data-segmentation/#exercise-6-validate-segments-with-logs","title":"Exercise 6: Validate Segments with Logs","text":"<p>Use Segments to reduce noise in log queries.</p> <ol> <li>Query logs without any Segment = more than 10k+ records.</li> <li>Apply App Segment for easytrade.</li> <li>Observe reduction in results.</li> </ol> <p></p> <p>Logs without Segment</p> <p></p> <p>Logs with App Segment</p>"},{"location":"7-data-segmentation/#exercise-7-validate-segments-with-traces","title":"Exercise 7: Validate Segments with Traces","text":"<p>Filter Distributed Traces using Segments.</p> <ol> <li>Open Distributed Traces and filter for failed requests.</li> <li>Apply App segment (easytrade).</li> <li>Observe filtered trace results.</li> </ol> <p></p> <p>Failed requests</p> <p></p> <p>Filtered traces</p>"},{"location":"7-data-segmentation/#exercise-8-validate-segments-with-metrics","title":"Exercise 8: Validate Segments with Metrics","text":"<p>Use Segments to scope dashboard tiles.</p> <ol> <li>Create a tile for k8s container CPU usage across workloads.</li> <li>Apply App segment (easytrade) to the tile.</li> <li>Observe scoped metric results.</li> </ol> <p></p> <p>Global notebook segment applied</p> <p></p> <p>Final dashboard view</p> <ul> <li>Let's continue</li> </ul>"},{"location":"8-data-partitioning-and-cost-allocation/","title":"8. Data partitioning and Cost allocation","text":""},{"location":"8-data-partitioning-and-cost-allocation/#data-partitioning-and-cost-allocation","title":"Data Partitioning and Cost Allocation","text":"<p>Since easytrade is growing fast and multiple teams are accessing logs and metrics across environments, performance and cost are becoming critical concerns. To stay ahead, Easytrade engineers need to implement a bucket strategy to optimize log storage and query performance. At the same time, they\u2019re introducing cost allocation tagging to track usage across teams and applications. This lab will guide you through designing a log bucket strategy and applying cost allocation metadata to a VM \u2014 helping Easytrade scale smart, not just fast.</p>"},{"location":"8-data-partitioning-and-cost-allocation/#learning-objectives","title":"\ud83c\udfaf Learning Objectives","text":"<ul> <li>Understand how buckets impact data retention, query performance, and cost.</li> <li>Design a log bucket strategy based on ingestion volume and dimensions.</li> <li>Learn how to apply cost allocation metadata using <code>dt.security_context</code>, <code>dt.cost.product</code>, and <code>dt.cost.costcenter</code>.</li> </ul>"},{"location":"8-data-partitioning-and-cost-allocation/#data-partitioning-bucket-strategy-for-logs","title":"Data Partitioning \u2013 Bucket Strategy for Logs","text":"<p>Why do buckets matter?</p> <ul> <li>Data Retention: Controls how long logs are stored - main use!</li> <li>Query Performance: Targeted buckets reduce scan time.</li> <li>Cost Efficiency: Less scan = lower DQL costs.</li> </ul> <p>You could technically rely on the default buckets, without creating custom ones. The advantage would be a reduced configuration management, but the drawback would be a decreased performance &amp; costs. That\u2019s the trade-off when desiging your bucket strategy.</p> <p>Keep that in mind especially for small accounts, you don\u2019t want to overcomplicate the solution. But for Enterprise accounts, a bucket strategy is required.</p> <p></p>"},{"location":"8-data-partitioning-and-cost-allocation/#examples","title":"Examples","text":"<p>Small scale customer ( &lt; 2TB/day )</p> <p>If your customer has a low ingestion volume (e.g., less than 2 TB/day), they\u2019ll likely operate within the default limit of 80 buckets per environment. In this case:</p> <ul> <li>Avoid creating too many buckets \u2014 especially at the team level.</li> <li>Instead, consider using record-level permissions within a few shared buckets.</li> <li>Focus on functional separation \u2014 split logs based on their purpose (e.g., infrastructure vs. application logs), rather than ownership.</li> </ul> <p>This approach keeps configuration simple and avoids unnecessary overhead.</p> <p>Large scale customer (250-1000 buckets)</p> <p>For enterprise customers with higher ingestion volumes and extended bucket limits:</p> <ul> <li>A multi-bucket strategy becomes essential.</li> <li>Buckets should be designed to support:</li> <li>Data retention policies</li> <li>Query performance optimization</li> <li>Cost control</li> <li>Access control per team or business unit</li> </ul> <p>Use meaningful dimensions like <code>app</code>, <code>business_unit</code>, or <code>stage</code> to partition logs.</p> <p>\ud83d\udca1 Remember: Custom buckets are primarily designed for data retention, but they also play a key role in access control and cost efficiency.</p>"},{"location":"8-data-partitioning-and-cost-allocation/#exercise-1-analyze-ingestion-volume","title":"Exercise 1: Analyze Ingestion Volume","text":"<p>Use dimensions like app, stage, or team to estimate log volume.</p> <p>Review the customer\u2019s log ingestion volume per app. You can do that by fetching all logs for your k8s cluster and then applying any of the created segments that will lower the result size as well as improve the performance.</p> <p>Think about how you would approach a customer with this kind of scenario. How would you split the logs? Would your customer want a standardized bucket approach per team? Or do they work more in a \"purpose\" fashion where logs are stored in different buckets based on their use/purpose? Or even solely based on the amount of data stored?</p>"},{"location":"8-data-partitioning-and-cost-allocation/#exercise-2-design-bucket-strategy","title":"Exercise 2: Design Bucket Strategy","text":"<p>Choose the right dimension to partition logs - in this case, we can go with the namespace name.</p> <ol> <li>Go to Settings &gt; Storage Management</li> <li>Click on \"+Bucket\"</li> <li>Create a new custom bucket for easytrade logs and choose your retention</li> <li>Go to Settings &gt; Process and Contextualize &gt; Logs</li> <li>Add a new dynamic routing rule with a route = <code>k8s.namespace.name == \"easytrade\"</code></li> <li>Add a new pipeline and in the last stage of the pipeline, add the bucket asignment rule.</li> <li>Fetch the logs again and check that your rule works.</li> </ol> <p>Please note - this is not an official recommendation for every customer scenario. Handling large buckets based on a namespace in a customer environment of many k8s clusters is most likely not a good idea if you're trying to accomplish a scalable approach. Think of using k8s cluster level if needed.</p>"},{"location":"8-data-partitioning-and-cost-allocation/#exercise-3-connect-buckets-to-access-control","title":"Exercise 3: Connect Buckets to Access Control","text":"<p>Use IAM to restrict log access by bucket.</p>"},{"location":"8-data-partitioning-and-cost-allocation/#exercise-4-cost-allocation","title":"Exercise 4: Cost Allocation","text":"<p>Dynatrace provides full-stack observability, which means cost allocation must account for:</p> <ul> <li>Host monitoring</li> <li>Signals tied to the host (e.g., Kubernetes cluster metrics, Logs etc.)</li> </ul> <p>This exercise focuses on configuring cost allocation for Full-Stack monitoring as well as for new Log Ingest &amp; Process cost allocation feature introduced in Dynatrace SaaS 1.324.</p> <p>Cost Allocation Overview </p> <p>Step-by-Step Instructions:</p> <ol> <li>To ensure only relevant entities are included in cost allocation follow the official documentation to configure the allow list.</li> <li>Tagging hosts is essential for accurate cost attribution. You\u2019ll configure host properties remotely on OneAgents.</li> <li>No manual configuration is needed for logs in this lab. Telemetry enrichment has already been set up and will automatically apply the necessary tagging for log ingest cost allocation for our <code>loginservice</code>.</li> <li>There is a difference between something that is possible to be cross-charged and something that is officially available within our Cost Allocation feature. <code>Log Management - Ingest &amp; Process</code> is available as of <code>1.324</code> which means that the Cost Allocation attributes <code>dt.cost.costcenter</code> and <code>dt.cost.product</code> will be on all Log Ingest Billing Usage Events (fetch dt.system.events). Therefore, this is officially supported by our Cost Allocation feature and will show up in Account Management.</li> <li></li> <li>To verify your configuration - go to demo.live &gt; Dashboards &gt; All Dashboards &gt; Download the dashboard \"DPS Cost Allocation - Usage &amp; Costs v1.3\". Upload it to your personal Dynatrace tenant. This dashboard will display cost allocation details based on your tagging and enrichment setup.</li> </ol> <ul> <li>Let's continue</li> </ul>"},{"location":"cleanup/","title":"9. Cleanup","text":"<p>Deleting the codespace from inside the container</p> <p>We like to make your life easier, for convenience there is a function loaded in the shell of the Codespace for deleting the codespace, just type <code>deleteCodespace</code>. This will trigger the deletion of the codespace.</p> <p>Another way to do this is by going to https://github.com/codespaces and delete the codespace.</p> <p>You may also want to deactivate or delete the API token needed for this lab.</p> <ul> <li>Ressources</li> </ul>"},{"location":"resources/","title":"Resources","text":""},{"location":"resources/#get-your-dynatrace-environment","title":"Get your Dynatrace environment","text":"<ul> <li>Create a Free Trial in Dynatrace</li> </ul>"},{"location":"resources/#documentation","title":"Documentation","text":"<ul> <li>Dynatrace documentation</li> </ul>"},{"location":"resources/#dynatrace-news","title":"Dynatrace news","text":"<ul> <li>Dynatrace Blog</li> </ul> <ul> <li>What's Next? </li> </ul>"},{"location":"whats-next/","title":"Whats next","text":"<p>More to come</p> <ul> <li>Stay tuned, more enablements are coming whith more advanced usecases...</li> </ul>"},{"location":"snippets/admonitions/","title":"Admonitions","text":"<p>Note</p> <p>This is a Note </p> <p>Abstract</p> <p>This is an abstract</p> <p>Tipp</p> <p>This is a tipp </p> <p>Success</p> <p>This is a success </p> <p>Question</p> <p>This is a success </p> <p>Failure</p> <p>This is a failure </p> <p>Danger</p> <p>This is a danger </p> <p>Info</p> <p>This is a info</p> <p>Warning</p> <p>This is a Warning </p> <p>This is an Example admonition</p> <p>This is an example</p> This is a bug and is collapsable <p>This is a bug</p>"},{"location":"snippets/disclaimer/","title":"Disclaimer","text":"<p>Support Policy</p> <p>Support is provided via GitHub issues only. The materials provided in this repository are offered \"as-is\" without any warranties, express or implied. Use them at your own risk.</p>"},{"location":"snippets/dt-enablement/","title":"Dt enablement","text":"<p>This codespace is powered by the Dynatrace Enablement Framework, this means that this codespace:</p> <ul> <li>can run in github codespaces, as a remote container or locally as docker container</li> <li>is crosscompiled for AMD and ARM architectures</li> <li>follows a set of standards and best practices for enhancing the user experience</li> </ul> <p>Want to learn more about it? We invite you to read this documentation</p>"},{"location":"snippets/grail-requirements/","title":"Grail requirements","text":"<p>Requirements</p> <ul> <li>A Grail enabled Dynatrace SaaS Tenant (sign up here).</li> <li>A GitHub account to interact with the demo repository.</li> </ul>"},{"location":"snippets/view-code/","title":"View code","text":"<p>View the Code</p> <p>The code for this repository is hosted on GitHub. Click the \"View Code on GitHub\" link above.</p>"}]}